{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Required Libraries\n",
        "\n"
      ],
      "metadata": {
        "id": "C_AwPkc-PaTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-09-11T21:11:11.121246Z",
          "iopub.execute_input": "2023-09-11T21:11:11.121509Z",
          "iopub.status.idle": "2023-09-11T21:11:11.458732Z",
          "shell.execute_reply.started": "2023-09-11T21:11:11.121484Z",
          "shell.execute_reply": "2023-09-11T21:11:11.457808Z"
        },
        "trusted": true,
        "id": "yADwUlbwk9ar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install evaluate\n",
        "!pip install rouge\n",
        "\n",
        "\n",
        "import torch\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "import nltk\n",
        "import spacy\n",
        "import string\n",
        "import evaluate  # Bleu\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import transformers\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import T5Tokenizer, T5Model, T5ForConditionalGeneration, T5TokenizerFast\n",
        "from datasets import load_dataset\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-11T21:11:20.787790Z",
          "iopub.execute_input": "2023-09-11T21:11:20.788666Z",
          "iopub.status.idle": "2023-09-11T21:12:27.726473Z",
          "shell.execute_reply.started": "2023-09-11T21:11:20.788629Z",
          "shell.execute_reply": "2023-09-11T21:12:27.725404Z"
        },
        "trusted": true,
        "id": "ViwoXIidk9ay",
        "outputId": "26681183-0339-4f5c-8c71-edc9aebd61ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.33.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.16.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\nCollecting evaluate\n  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.23.5)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.0.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.3.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.15)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2023.9.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.16.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.18.0)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (11.0.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.8.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2023.7.22)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.0\nCollecting rouge\n  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from rouge) (1.16.0)\nInstalling collected packages: rouge\nSuccessfully installed rouge-1.0.1\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the Dataset, Tokenizer, Model and Optimizer"
      ],
      "metadata": {
        "id": "J3SA5bUEPuQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_datasets = load_dataset(\"vicgalle/alpaca-gpt4\")\n",
        "raw_datasets"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-11T21:11:11.461189Z",
          "iopub.execute_input": "2023-09-11T21:11:11.461974Z",
          "iopub.status.idle": "2023-09-11T21:11:16.100633Z",
          "shell.execute_reply.started": "2023-09-11T21:11:11.461940Z",
          "shell.execute_reply": "2023-09-11T21:11:16.099527Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "1747557afc0f4c6c9d342b871a96f56d",
            "d5d418c8d1dc4470b76b4568b4ff5754",
            "3466683e065c488bb5c1c72d75fbf3b3",
            "fe27d461a0754ea8b63915d87bf6beaf"
          ]
        },
        "id": "qEPTnSQnk9av",
        "outputId": "2afc271d-fbd2-4501-a5ba-86380e80b0b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Downloading and preparing dataset parquet/vicgalle--alpaca-gpt4 to /root/.cache/huggingface/datasets/parquet/vicgalle--alpaca-gpt4-1e85e31ce0639161/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901...\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1747557afc0f4c6c9d342b871a96f56d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data:   0%|          | 0.00/48.4M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d5d418c8d1dc4470b76b4568b4ff5754"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3466683e065c488bb5c1c72d75fbf3b3"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/parquet/vicgalle--alpaca-gpt4-1e85e31ce0639161/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901. Subsequent calls will reuse this data.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe27d461a0754ea8b63915d87bf6beaf"
            }
          },
          "metadata": {}
        },
        {
          "execution_count": 2,
          "output_type": "execute_result",
          "data": {
            "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['instruction', 'input', 'output', 'text'],\n        num_rows: 52002\n    })\n})"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TOKENIZER = T5TokenizerFast.from_pretrained(\"t5-base\")\n",
        "MODEL = T5ForConditionalGeneration.from_pretrained(\"t5-base\", return_dict=True)\n",
        "OPTIMIZER = Adam(MODEL.parameters(), lr=0.00001)\n",
        "Q_LEN = 256   # Question Length\n",
        "T_LEN = 512    # Target Length\n",
        "BATCH_SIZE = 4\n",
        "DEVICE = \"cuda:0\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-11T21:12:27.728658Z",
          "iopub.execute_input": "2023-09-11T21:12:27.729053Z",
          "iopub.status.idle": "2023-09-11T21:12:37.880474Z",
          "shell.execute_reply.started": "2023-09-11T21:12:27.729018Z",
          "shell.execute_reply": "2023-09-11T21:12:37.879424Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "6251b308bda64d9ba8c47af67adbc5c3",
            "131af734e62c4fb3aa92a23ae3f38dac",
            "5468f871fdc540ae86e3ac161750db7b",
            "e8dbfc7f5dd04ab7b55970f3a54c3e05",
            "cd45a95b33c24f07916fee0b72897755"
          ]
        },
        "id": "oTenIZYOk9az",
        "outputId": "c8e97833-c241-41c9-afde-38f7632557de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6251b308bda64d9ba8c47af67adbc5c3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "131af734e62c4fb3aa92a23ae3f38dac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5468f871fdc540ae86e3ac161750db7b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e8dbfc7f5dd04ab7b55970f3a54c3e05"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd45a95b33c24f07916fee0b72897755"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre Processing"
      ],
      "metadata": {
        "id": "D866WdtGQJDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, DatasetDict\n",
        "\n",
        "def convert_example(example):\n",
        "    return {\n",
        "        \"context\": example[\"input\"],  # Assuming 'input' is your context\n",
        "        \"question\": example[\"instruction\"],  # Assuming 'instruction' is your question\n",
        "        \"answer\": example[\"output\"]  # Assuming 'output' is your answer\n",
        "    }\n",
        "\n",
        "# Apply the conversion function to each split of the dataset\n",
        "converted_datasets = {split: raw_datasets[split].map(convert_example) for split in raw_datasets.keys()}\n",
        "\n",
        "# Create a new dataset with the converted splits\n",
        "new_dataset = DatasetDict(converted_datasets)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-11T21:12:37.881850Z",
          "iopub.execute_input": "2023-09-11T21:12:37.882389Z",
          "iopub.status.idle": "2023-09-11T21:12:46.212774Z",
          "shell.execute_reply.started": "2023-09-11T21:12:37.882354Z",
          "shell.execute_reply": "2023-09-11T21:12:46.211418Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "bfa1578731964c9286efb63012517211"
          ]
        },
        "id": "7vsrRm9Fk9a0",
        "outputId": "f845b24d-ebdb-448c-c918-a033377495a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/52002 [00:00<?, ?ex/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bfa1578731964c9286efb63012517211"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.DataFrame(new_dataset['train'])\n",
        "data.drop\n",
        "columns_to_drop = ['instruction','input','output','text']\n",
        "data = data.drop(columns=columns_to_drop)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-11T21:12:46.221008Z",
          "iopub.execute_input": "2023-09-11T21:12:46.221861Z",
          "iopub.status.idle": "2023-09-11T21:12:52.722937Z",
          "shell.execute_reply.started": "2023-09-11T21:12:46.221822Z",
          "shell.execute_reply": "2023-09-11T21:12:52.721947Z"
        },
        "trusted": true,
        "id": "eavQQyYLk9a0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-11T21:12:52.728360Z",
          "iopub.execute_input": "2023-09-11T21:12:52.728671Z",
          "iopub.status.idle": "2023-09-11T21:12:52.745307Z",
          "shell.execute_reply.started": "2023-09-11T21:12:52.728645Z",
          "shell.execute_reply": "2023-09-11T21:12:52.744298Z"
        },
        "trusted": true,
        "id": "oHCkeZHsk9a1",
        "outputId": "68b12661-cf98-4fc9-e2ee-3284c7c437c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 7,
          "output_type": "execute_result",
          "data": {
            "text/plain": "  context                                           question  \\\n0                       Give three tips for staying healthy.   \n1                         What are the three primary colors?   \n2                         Describe the structure of an atom.   \n3                           How can we reduce air pollution?   \n4          Describe a time when you had to make a difficu...   \n\n                                              answer  \n0  1. Eat a balanced and nutritious diet: Make su...  \n1  The three primary colors are red, blue, and ye...  \n2  An atom is the basic building block of all mat...  \n3  There are several ways to reduce air pollution...  \n4  As an AI assistant, I do not have my own perso...  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>context</th>\n      <th>question</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>Give three tips for staying healthy.</td>\n      <td>1. Eat a balanced and nutritious diet: Make su...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>What are the three primary colors?</td>\n      <td>The three primary colors are red, blue, and ye...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>Describe the structure of an atom.</td>\n      <td>An atom is the basic building block of all mat...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>How can we reduce air pollution?</td>\n      <td>There are several ways to reduce air pollution...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>Describe a time when you had to make a difficu...</td>\n      <td>As an AI assistant, I do not have my own perso...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class QA_Dataset(Dataset):\n",
        "    def __init__(self, tokenizer, dataframe, q_len, t_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.q_len = q_len\n",
        "        self.t_len = t_len\n",
        "        self.dataframe = dataframe\n",
        "        self.questions = self.dataframe[\"question\"]\n",
        "        self.context = self.dataframe[\"context\"]\n",
        "        self.answer = self.dataframe['answer']\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.questions)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        question = self.questions[idx]\n",
        "        context = self.context[idx]\n",
        "        answer = self.answer[idx]\n",
        "\n",
        "        question_tokenized = self.tokenizer(question, context, max_length=self.q_len, padding=\"max_length\",\n",
        "                                                    truncation=True, pad_to_max_length=True, add_special_tokens=True)\n",
        "        answer_tokenized = self.tokenizer(answer, max_length=self.t_len, padding=\"max_length\",\n",
        "                                          truncation=True, pad_to_max_length=True, add_special_tokens=True)\n",
        "\n",
        "        labels = torch.tensor(answer_tokenized[\"input_ids\"], dtype=torch.long)\n",
        "        labels[labels == 0] = -100\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": torch.tensor(question_tokenized[\"input_ids\"], dtype=torch.long),\n",
        "            \"attention_mask\": torch.tensor(question_tokenized[\"attention_mask\"], dtype=torch.long),\n",
        "            \"labels\": labels,\n",
        "            \"decoder_attention_mask\": torch.tensor(answer_tokenized[\"attention_mask\"], dtype=torch.long)\n",
        "        }"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-11T21:12:52.746778Z",
          "iopub.execute_input": "2023-09-11T21:12:52.747294Z",
          "iopub.status.idle": "2023-09-11T21:12:52.761262Z",
          "shell.execute_reply.started": "2023-09-11T21:12:52.747259Z",
          "shell.execute_reply": "2023-09-11T21:12:52.760383Z"
        },
        "trusted": true,
        "id": "cL7-Y0tfk9a2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Splitting the data"
      ],
      "metadata": {
        "id": "0v4l5iC6Qez9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataloader\n",
        "\n",
        "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "train_sampler = RandomSampler(train_data.index)\n",
        "val_sampler = RandomSampler(val_data.index)\n",
        "\n",
        "qa_dataset = QA_Dataset(TOKENIZER, data, Q_LEN, T_LEN)\n",
        "\n",
        "train_loader = DataLoader(qa_dataset, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
        "val_loader = DataLoader(qa_dataset, batch_size=BATCH_SIZE, sampler=val_sampler)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-11T21:12:52.762580Z",
          "iopub.execute_input": "2023-09-11T21:12:52.763534Z",
          "iopub.status.idle": "2023-09-11T21:12:52.790504Z",
          "shell.execute_reply.started": "2023-09-11T21:12:52.763481Z",
          "shell.execute_reply": "2023-09-11T21:12:52.789524Z"
        },
        "trusted": true,
        "id": "1yiy4hz_k9a2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Tuning"
      ],
      "metadata": {
        "id": "JNhKBZF-Qib5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = 0\n",
        "val_loss = 0\n",
        "train_batch_count = 0\n",
        "val_batch_count = 0\n",
        "\n",
        "for epoch in range(2):\n",
        "    MODEL.to(DEVICE)\n",
        "    OPTIMIZER = Adam(MODEL.parameters(), lr=0.00001)\n",
        "\n",
        "    # Inside your training loop\n",
        "    for batch in tqdm(train_loader, desc=\"Training batches\"):\n",
        "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
        "        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
        "        labels = batch[\"labels\"].to(DEVICE)\n",
        "        decoder_attention_mask = batch[\"decoder_attention_mask\"].to(DEVICE)\n",
        "\n",
        "        outputs = MODEL(\n",
        "                          input_ids=input_ids,\n",
        "                          attention_mask=attention_mask,\n",
        "                          labels=labels,\n",
        "                          decoder_attention_mask=decoder_attention_mask\n",
        "                        )\n",
        "\n",
        "        OPTIMIZER.zero_grad()\n",
        "        outputs.loss.backward()\n",
        "        OPTIMIZER.step()\n",
        "        train_loss += outputs.loss.item()\n",
        "        train_batch_count += 1\n",
        "\n",
        "    #Evaluation\n",
        "    MODEL.eval()\n",
        "    for batch in tqdm(val_loader, desc=\"Validation batches\"):\n",
        "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
        "        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
        "        labels = batch[\"labels\"].to(DEVICE)\n",
        "        decoder_attention_mask = batch[\"decoder_attention_mask\"].to(DEVICE)\n",
        "\n",
        "        outputs = MODEL(\n",
        "                          input_ids=input_ids,\n",
        "                          attention_mask=attention_mask,\n",
        "                          labels=labels,\n",
        "                          decoder_attention_mask=decoder_attention_mask\n",
        "                        )\n",
        "\n",
        "        OPTIMIZER.zero_grad()\n",
        "        outputs.loss.backward()\n",
        "        OPTIMIZER.step()\n",
        "        val_loss += outputs.loss.item()\n",
        "        val_batch_count += 1\n",
        "\n",
        "    print(f\"{epoch+1}/{2} -> Train loss: {train_loss / train_batch_count}\\tValidation loss: {val_loss/val_batch_count}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-11T21:16:58.052949Z",
          "iopub.execute_input": "2023-09-11T21:16:58.054028Z",
          "iopub.status.idle": "2023-09-11T23:32:39.976336Z",
          "shell.execute_reply.started": "2023-09-11T21:16:58.053976Z",
          "shell.execute_reply": "2023-09-11T23:32:39.975166Z"
        },
        "trusted": true,
        "id": "fVT5GCx1k9a3",
        "outputId": "3242250e-e65a-41af-8566-01d8a7d4fc59"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "Training batches: 100%|██████████| 10401/10401 [55:56<00:00,  3.10it/s]\nValidation batches: 100%|██████████| 2601/2601 [13:17<00:00,  3.26it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "1/2 -> Train loss: 2.3907446466710818\tValidation loss: 1.8951716420972224\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training batches: 100%|██████████| 10401/10401 [53:10<00:00,  3.26it/s]\nValidation batches: 100%|██████████| 2601/2601 [13:18<00:00,  3.26it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "2/2 -> Train loss: 2.0866022048466664\tValidation loss: 1.731062575286739\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving the model"
      ],
      "metadata": {
        "id": "-3tV7miYQqWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL.save_pretrained(\"qa_model\")\n",
        "TOKENIZER.save_pretrained(\"qa_tokenizer\")\n",
        "\n",
        "# Saved files\n",
        "\"\"\"('qa_tokenizer/tokenizer_config.json',\n",
        " 'qa_tokenizer/special_tokens_map.json',\n",
        " 'qa_tokenizer/spiece.model',\n",
        "'qa_tokenizer/added_tokens.json',\n",
        "'qa_tokenizer/tokenizer.json')\"\"\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-11T23:32:41.296779Z",
          "iopub.execute_input": "2023-09-11T23:32:41.297351Z",
          "iopub.status.idle": "2023-09-11T23:32:43.883845Z",
          "shell.execute_reply.started": "2023-09-11T23:32:41.297318Z",
          "shell.execute_reply": "2023-09-11T23:32:43.882724Z"
        },
        "trusted": true,
        "id": "5zVa4fRrk9a6",
        "outputId": "03b9be21-b8aa-457e-a6ef-f651c0068953"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 14,
          "output_type": "execute_result",
          "data": {
            "text/plain": "\"('qa_tokenizer/tokenizer_config.json',\\n 'qa_tokenizer/special_tokens_map.json',\\n 'qa_tokenizer/spiece.model',\\n'qa_tokenizer/added_tokens.json',\\n'qa_tokenizer/tokenizer.json')\""
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predictions"
      ],
      "metadata": {
        "id": "JQJzfgy7Qu9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_answer(context, question, ref_answer=None):\n",
        "    inputs = TOKENIZER(question, context, max_length=Q_LEN, padding=\"max_length\", truncation=True, add_special_tokens=True)\n",
        "\n",
        "    input_ids = torch.tensor(inputs[\"input_ids\"], dtype=torch.long).to(DEVICE).unsqueeze(0)\n",
        "    attention_mask = torch.tensor(inputs[\"attention_mask\"], dtype=torch.long).to(DEVICE).unsqueeze(0)\n",
        "\n",
        "    outputs = MODEL.generate(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    predicted_answer = TOKENIZER.decode(outputs.flatten(), skip_special_tokens=True)\n",
        "\n",
        "    if ref_answer:\n",
        "        # Load the Bleu metric\n",
        "        bleu = evaluate.load(\"google_bleu\")\n",
        "        score = bleu.compute(predictions=[predicted_answer],\n",
        "                            references=[ref_answer])\n",
        "\n",
        "        print(\"Context: \\n\", context)\n",
        "        print(\"\\n\")\n",
        "        print(\"Question: \\n\", question)\n",
        "        return {\n",
        "            \"Reference Answer: \": ref_answer,\n",
        "            \"Predicted Answer: \": predicted_answer,\n",
        "            \"BLEU Score: \": score\n",
        "        }\n",
        "    else:\n",
        "        return predicted_answer"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-11T23:32:48.548015Z",
          "iopub.execute_input": "2023-09-11T23:32:48.549107Z",
          "iopub.status.idle": "2023-09-11T23:32:48.559980Z",
          "shell.execute_reply.started": "2023-09-11T23:32:48.549070Z",
          "shell.execute_reply": "2023-09-11T23:32:48.558942Z"
        },
        "trusted": true,
        "id": "wK7To3dgk9a7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context = ''\n",
        "question = 'Write a title on a story written on moon'\n",
        "predict_answer(context,question)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-11T23:41:03.477866Z",
          "iopub.execute_input": "2023-09-11T23:41:03.478292Z",
          "iopub.status.idle": "2023-09-11T23:41:03.817946Z",
          "shell.execute_reply.started": "2023-09-11T23:41:03.478261Z",
          "shell.execute_reply": "2023-09-11T23:41:03.816933Z"
        },
        "trusted": true,
        "id": "Oh1z_cBPk9a8",
        "outputId": "ce3cab31-d507-4dd8-bc15-8cb04fbc4185"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 27,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'\"The Moon\\'s Journey: A Memoir of a Man on the Edge of'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RtIh9Yz5k9a9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}